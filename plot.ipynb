{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from enum import Enum\n",
    "import math\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def run_command_no_output(command):\n",
    "    try:\n",
    "        subprocess.check_call(command)\n",
    "        return True\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"Failed to run: {' '.join(command)}\")\n",
    "        return False\n",
    "\n",
    "class Metric(Enum):\n",
    "    server_runtime_ms = 0\n",
    "    max_payload_size_B = 1\n",
    "    query_size_B = 2\n",
    "    response_size_B = 3\n",
    "\n",
    "rlwe_dict = {\n",
    "    Metric.max_payload_size_B : (lambda data: data['Item size (B)']),\n",
    "    Metric.server_runtime_ms : (lambda data: data['server time (ms)']),\n",
    "    Metric.query_size_B : (lambda data: data['request size (B)']/2),\n",
    "    Metric.response_size_B : (lambda data: data['response size (B)']),\n",
    "\n",
    "}\n",
    "\n",
    "spiral_dict ={\n",
    "    Metric.max_payload_size_B : (lambda data: data['Item size (B)']),\n",
    "    Metric.server_runtime_ms : (lambda data: data['total_us']/1000),\n",
    "    Metric.query_size_B : (lambda data: (data['param_sz'] + data['query_sz'])),\n",
    "    Metric.response_size_B : (lambda data: data['resp_sz']),\n",
    "}\n",
    "\n",
    "functions = {\n",
    "    'RLWE_All_Keys' : rlwe_dict,\n",
    "    'RLWE_Whispir_3_Keys' : rlwe_dict,\n",
    "    'RLWE_Whispir_2_Keys' : rlwe_dict,\n",
    "    'sealpir' : { \n",
    "        Metric.max_payload_size_B : (lambda data: data['max_element_size']),\n",
    "        Metric.server_runtime_ms : (lambda data: data['PIRServer_reply_generation_time']),\n",
    "        Metric.query_size_B : (lambda data: data['size_gal_keys'] + data['query_size']),\n",
    "        Metric.response_size_B : (lambda data: data['reply_size']),\n",
    "    }, \n",
    "    'fastpir' : {\n",
    "        Metric.max_payload_size_B : (lambda data: data['Item size (B)']),\n",
    "        Metric.server_runtime_ms : (lambda data: data['Response generation time (us)']/1000),\n",
    "        Metric.query_size_B : (lambda data: data['Query size (B)']),\n",
    "        Metric.response_size_B : (lambda data: data['Response size (B)']),\n",
    "    },\n",
    "    'onionpir' : {\n",
    "        Metric.max_payload_size_B : (lambda data: data['Item size (B)']),\n",
    "        Metric.server_runtime_ms : (lambda data: data['Reply time (ms)']),\n",
    "        Metric.query_size_B : (lambda data: (data['Gal Keys (KB)'] + data['Encrypted Secret Key (KB)'] + data['Query size (KB)']) * 1024),\n",
    "        Metric.response_size_B : (lambda data: data['Reply size (KB)'] * 1024),\n",
    "    },\n",
    "    'spiral' : spiral_dict,\n",
    "    'spiral-pack' : spiral_dict,\n",
    "    'spiral-stream' : spiral_dict,\n",
    "    'spiral-stream-pack' : spiral_dict,\n",
    "}\n",
    "\n",
    "run_command_no_output([\"mkdir\", \"-p\", 'results'])\n",
    "\n",
    "TARGET_PAYLOAD_SIZE_B = 256*1024\n",
    "for name in functions.keys():\n",
    "    with open(f\"results/{name}.csv\", \"w\") as f:\n",
    "        f.write(\"num_rows, target_payload_size_B, runtime_s, communication_KB\\n\")\n",
    "    for log_num_rows in [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]:\n",
    "        num_rows = 2**log_num_rows\n",
    "        directory_to_logs = f\"logs/logs-{num_rows}-0/{name}\"\n",
    "        # path_to_file = f\"logs/logs-{num_rows}-0/{name}.json\"\n",
    "        all_files = os.listdir(directory_to_logs)\n",
    "        # Filter to include only .json files\n",
    "        json_files = [file for file in all_files if file.endswith('.json')]\n",
    "\n",
    "        # Iterate over each json file\n",
    "        for json_file in json_files:\n",
    "        # if os.path.exists(path_to_file):\n",
    "            path_to_file = os.path.join(directory_to_logs, json_file)\n",
    "            with open(path_to_file) as f:\n",
    "                data = json.load(f)\n",
    "                funcs = functions[name]\n",
    "                try:\n",
    "                    SCALAR = math.ceil(TARGET_PAYLOAD_SIZE_B / funcs[Metric.max_payload_size_B](data))\n",
    "                except Exception as e:\n",
    "                    SCALAR = None\n",
    "                # runtime\n",
    "                try:\n",
    "                    runtime_s = (funcs[Metric.server_runtime_ms](data) * SCALAR) / 1000\n",
    "                except Exception as e:\n",
    "                    runtime_s = None\n",
    "                \n",
    "                try:\n",
    "                    communication_KB = (funcs[Metric.query_size_B](data) + funcs[Metric.response_size_B](data) * SCALAR) / (1024)\n",
    "                except Exception as e:\n",
    "                    communication_KB = None\n",
    "\n",
    "                # print(f\"{name} {num_rows} ({runtime_s} s) ({communication_KB} KB)\")\n",
    "                with open(f\"results/{name}.csv\", \"a\") as f:\n",
    "                    if TARGET_PAYLOAD_SIZE_B is None:\n",
    "                        TARGET_PAYLOAD_SIZE_B = \" \"\n",
    "                    if runtime_s is None:\n",
    "                        runtime_s = \" \"\n",
    "                    if communication_KB is None:\n",
    "                        communication_KB = \" \"\n",
    "                    f.write(f\"{num_rows}, {TARGET_PAYLOAD_SIZE_B}, {runtime_s}, {communication_KB}\\n\")\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
